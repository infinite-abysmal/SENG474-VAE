{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn import model_selection\n",
    "\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to either credit or ether; NOTE: credit not currently working for a few later functions\n",
    "dataset = 'credit'\n",
    "\n",
    "#NOTE: I added these to the gitignore\n",
    "model_save_file = 'stored_models.pickle'\n",
    "info_save_file = 'model_info.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'ether':\n",
    "    df_transactions = pd.read_csv('archive/transaction_dataset.csv')\n",
    "\n",
    "    #create a copy in which the fraud flag is enabled, for later reference\n",
    "    df_transactions_copy = df_transactions.copy()\n",
    "\n",
    "    #these rows are all useless/would cause bad outcomes\n",
    "    df_transactions = df_transactions.drop(columns=['FLAG', 'Index'])\n",
    "\n",
    "    transactions = df_transactions.to_numpy()\n",
    "\n",
    "elif dataset == 'credit':\n",
    "    df_transactions = pd.read_csv('archive/credit_card_transactions.csv')\n",
    "\n",
    "    #create a copy in which the fraud flag is enabled, for later reference\n",
    "    df_transactions_copy = df_transactions.copy()\n",
    "\n",
    "    #these rows are all useless/would cause bad outcomes\n",
    "    df_transactions = df_transactions.drop(columns=['is_fraud', 'first', 'last', 'city', 'street', 'state', 'trans_num'])\n",
    "\n",
    "    transactions = df_transactions.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'credit':\n",
    "    column_ids = df_transactions.columns\n",
    "\n",
    "    unique_indices = {}\n",
    "    unique_indices_values = {}\n",
    "\n",
    "    X = np.ndarray(transactions.shape)\n",
    "\n",
    "    zero_time = datetime.fromordinal(1)\n",
    "\n",
    "    #this section is kind of abstract\n",
    "    #for every element of the dataset\n",
    "    for i in range(X.shape[0]):\n",
    "        #for every component of that element\n",
    "        for j in range(X.shape[1]):\n",
    "            #if that component is a number, it stays as it is\n",
    "            if isinstance(transactions[i, j], int) or isinstance(transactions[i, j], float):\n",
    "                X[i, j] = transactions[i, j]\n",
    "            \n",
    "            #handle datetime as seconds since 0\n",
    "            elif column_ids[j] == 'trans_date_trans_time':\n",
    "                #convert string to datetime object\n",
    "                dt = datetime.strptime(transactions[i, j], \"%Y-%m-%d %H:%M:%S\")\n",
    "                #convert to timedelta object by subtracting the 0 time\n",
    "                td = dt - zero_time\n",
    "\n",
    "                X[i, j] = td.total_seconds()\n",
    "\n",
    "            #handle dob as seconds since 0\n",
    "            elif column_ids[j] == 'dob':\n",
    "                #convert string to datetime object\n",
    "                dt = datetime.strptime(transactions[i, j], \"%Y-%m-%d\")\n",
    "                #convert to timedelta object by subtracting the 0 time\n",
    "                td = dt - zero_time\n",
    "\n",
    "                X[i, j] = td.total_seconds()\n",
    "\n",
    "            #if it is not a number, assign an integer to each unique value which appears\n",
    "            #ex, if name was a column, we might have 'Bob'=1, 'Cindy'=2, etc\n",
    "            else:\n",
    "                if not j in unique_indices:\n",
    "                    unique_indices[j] = {}\n",
    "                    unique_indices_values[j] = 0\n",
    "                if not transactions[i, j] in unique_indices[j]:\n",
    "                    unique_indices[j][transactions[i, j]] = unique_indices_values[j]\n",
    "                    unique_indices_values[j] += 1\n",
    "                X[i, j] = unique_indices[j][transactions[i, j]]\n",
    "            \n",
    "            #replace nan values with 0, since nan is not permissable in a BGM\n",
    "            #might be wise to replace with something else?\n",
    "            if math.isnan(X[i, j]):\n",
    "                X[i, j] = 0\n",
    "            \n",
    "    #in the ether dataset, index 13 breaks the solver, for some reason; remove it\n",
    "    excluded_indices = [13]\n",
    "    included_indices = [i for i in range(X.shape[1]) if i not in excluded_indices]\n",
    "\n",
    "    #I was pleasantly surprised numpy allowed this type of indexing\n",
    "    X = X[:, included_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'ether':\n",
    "\n",
    "    unique_indices = {}\n",
    "    unique_indices_values = {}\n",
    "\n",
    "    X = np.ndarray(transactions.shape)\n",
    "\n",
    "    #this section is kind of abstract\n",
    "    #for every element of the dataset\n",
    "    for i in range(X.shape[0]):\n",
    "        #for every component of that element\n",
    "        for j in range(X.shape[1]):\n",
    "            #if that component is a number, it stays as it is\n",
    "            if isinstance(transactions[i, j], int) or isinstance(transactions[i, j], float):\n",
    "                X[i, j] = transactions[i, j]\n",
    "            \n",
    "            #if it is not a number, assign an integer to each unique value which appears\n",
    "            #ex, if name was a column, we might have 'Bob'=1, 'Cindy'=2, etc\n",
    "            else:\n",
    "                if not j in unique_indices:\n",
    "                    unique_indices[j] = {}\n",
    "                    unique_indices_values[j] = 0\n",
    "                if not transactions[i, j] in unique_indices[j]:\n",
    "                    unique_indices[j][transactions[i, j]] = unique_indices_values[j]\n",
    "                    unique_indices_values[j] += 1\n",
    "                X[i, j] = unique_indices[j][transactions[i, j]]\n",
    "            \n",
    "            #replace nan values with 0, since nan is not permissable in a BGM\n",
    "            #might be wise to replace with something else?\n",
    "            if math.isnan(X[i, j]):\n",
    "                X[i, j] = 0\n",
    "    \n",
    "    #in the ether dataset, index 22 breaks the solver, for some reason; remove it\n",
    "    excluded_indices = [22]\n",
    "    included_indices = [i for i in range(X.shape[1]) if i not in excluded_indices]\n",
    "\n",
    "    #I was pleasantly surprised numpy allowed this type of indexing\n",
    "    X = X[:, included_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurements(log_probs:np.ndarray, transactions_df:pd.DataFrame, train_size:int=0, \n",
    "                     dynamic_epsilon:bool=True, \n",
    "                     score_function:None=lambda tps,fps,tns,fns: tps**1.3 - fps + tns - fns**1.3, \n",
    "                     epsilon:float=-200, test_range:int=400, test_step:int=5):\n",
    "    '''\n",
    "    gets the number of False Positives, True Positives, False Negatives, \n",
    "    True Negatives, and the best separating epsilon (if dynamic_epsilon=True)\n",
    "    score_function is a maximization function\n",
    "    '''\n",
    "\n",
    "    # determine which epsilon gives the best results (if dynamic is on)\n",
    "    best_score = 0\n",
    "    if dynamic_epsilon:\n",
    "        # for each test epsilon in range \n",
    "        # Max epsilon -> Max epsilon - test range (to prevent cases with insane length)\n",
    "        for test_epsilon in range(int(max(log_probs)), int(max(log_probs))-test_range, -test_step):\n",
    "            tps = 0\n",
    "            fps = 0\n",
    "            tns = 0\n",
    "            fns = 0\n",
    "\n",
    "            # for each probability\n",
    "            for i in range(log_probs.shape[0]):\n",
    "                #get whether or not a data point is fraud; NOTE: needs a rework\n",
    "                if dataset == 'ether': \n",
    "                    flag = transactions_df.iloc[i + train_size][\"FLAG\"]\n",
    "                elif dataset == 'credit': \n",
    "                    flag = transactions_df.iloc[i + train_size]['is_fraud']\n",
    "                \n",
    "                # if the element is marked as fraud, determine whether or not it is fraud\n",
    "                if log_probs[i] < test_epsilon:\n",
    "                    if flag == 1: tps += 1\n",
    "                    else: fps += 1\n",
    "                else:\n",
    "                   if flag == 1: fns += 1\n",
    "                   else: tns += 1 \n",
    "            \n",
    "            # if the score is the best, it becomes the best score\n",
    "            fscore = score_function(tps, fps, tns, fns)\n",
    "            if fscore > best_score:\n",
    "                epsilon = test_epsilon\n",
    "                best_score = fscore\n",
    "\n",
    "    #initialize the return values\n",
    "    fp, tp, fn, tn = 0,0,0,0\n",
    "    flags = 0\n",
    "\n",
    "    for i in range(log_probs.shape[0]):\n",
    "        #determine whether or not the element is actually fraud\n",
    "        #i + train_size gives the index in the training set. This will need to be fixed later\n",
    "        if dataset == 'ether': \n",
    "            flag = transactions_df.iloc[i + train_size][\"FLAG\"]\n",
    "        elif dataset == 'credit': \n",
    "            flag = transactions_df.iloc[i + train_size]['is_fraud']\n",
    "\n",
    "        # if the element is not fraud\n",
    "        if flag == 0:\n",
    "            #if it is marked as fraud\n",
    "            if log_probs[i] < epsilon: \n",
    "                #increment false positives\n",
    "                fp += 1\n",
    "            else: \n",
    "                #increment true negatives\n",
    "                tn += 1\n",
    "        #if the element is fraud\n",
    "        if flag == 1:\n",
    "            flags += 1\n",
    "            #if it is marked as fraud\n",
    "            if log_probs[i] < epsilon: \n",
    "                #increment true positives\n",
    "                tp += 1\n",
    "            else: \n",
    "                #increment false negatives\n",
    "                fn += 1\n",
    "\n",
    "    # keeping these for debug purposes\n",
    "    # print(f'FP:{fp}, TP:{tp}, FN:{fn}, TN:{tn}, pos:{pos}, neg:{neg}, flags:{flags}')\n",
    "    # print(f'correctly classified fraud:{tp}/{flags} ({tp/flags*100}%), incorrectly classified normal: {fp}/{(X_test.shape[0]-flags)} ({fp/(X_test.shape[0]-flags)*100}%)')\n",
    "    # print(f'Normal Labels: {[i for i in sorted(zip(good_labels.keys(), good_labels.values()), key=lambda a: -a[1])]}')\n",
    "    # print(f'Fraudulent Labels: {[i for i in sorted(zip(evil_labels.keys(), evil_labels.values()), key=lambda a: -a[1])]}')\n",
    "\n",
    "    return fp, tp, fn, tn, epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is kept separate so that I don't accidentally fuck up my experiments by running it\n",
    "#use to reset the training\n",
    "trained_models = {}\n",
    "output_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use try catch to prevent errors if the save files are not present\n",
    "\n",
    "try:\n",
    "    #if it exists, load the previously trained models\n",
    "    model_input_file = open(model_save_file, 'rb')\n",
    "\n",
    "    #store them back in the trained models dictionary\n",
    "    unpickler = pickle.Unpickler(model_input_file)\n",
    "    trained_models = unpickler.load()\n",
    "\n",
    "    model_input_file.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    #if it exists, load the previously gathered data\n",
    "    info_input_file = open(info_save_file, 'rb')\n",
    "\n",
    "    #store them back in the output info dictionary\n",
    "    unpickler = pickle.Unpickler(info_input_file)\n",
    "    output_info = unpickler.load()\n",
    "\n",
    "    info_input_file.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = BayesianGaussianMixture().get_params(0)\n",
    "\n",
    "default['n_components'] = 10 #the defualt is 1, which is useless\n",
    "default['weight_concentration_prior'] = 10 #the default is 0, which is bad\n",
    "default['verbose'] = False #switch to true, to fill your screen with numbers\n",
    "default['max_iter'] = 1000 #defaults to 100, but that often fails to converge\n",
    "default['random_state'] = 0 #to keep experiments consistent\n",
    "\n",
    "def bgm(parameters):\n",
    "    '''Returns a BayesianGaussianMixture based on the parameters\\n\n",
    "    parameters can be either a key or a dictionary\n",
    "    '''\n",
    "    params = dict(parameters)\n",
    "    comps = default\n",
    "\n",
    "    for key in params:\n",
    "        comps[key] = params[key]\n",
    "\n",
    "    return BayesianGaussianMixture(covariance_prior=comps['covariance_prior'],\n",
    "        covariance_type=comps['covariance_type'],\n",
    "        degrees_of_freedom_prior=comps['degrees_of_freedom_prior'],\n",
    "        init_params=comps['init_params'],\n",
    "        max_iter=comps['max_iter'],\n",
    "        mean_precision_prior=comps['mean_precision_prior'],\n",
    "        mean_prior=comps['mean_prior'],\n",
    "        n_components=comps['n_components'],\n",
    "        n_init=comps['n_init'],\n",
    "        random_state=comps['random_state'],\n",
    "        reg_covar=comps['reg_covar'],\n",
    "        tol=comps['tol'],\n",
    "        verbose=comps['verbose'],\n",
    "        verbose_interval=comps['verbose_interval'],\n",
    "        warm_start=comps['warm_start'],\n",
    "        weight_concentration_prior=comps['weight_concentration_prior'],\n",
    "        weight_concentration_prior_type=comps['weight_concentration_prior_type'])\n",
    "\n",
    "def key(dic, additional_params:dict={}):\n",
    "    '''uses a parameter dictionary to save keys for easier lookup, from a dictionary\\n\n",
    "    Ex. trained_models[key({'tol':1.0, 'fold':2})] will give back the model with those parameters'''\n",
    "    dictionary = dict(dic)\n",
    "    for param in additional_params:\n",
    "        dictionary[param] = additional_params[param]\n",
    "\n",
    "    return frozenset(sorted(zip(dictionary.keys(), dictionary.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({('demonstration key', 7), ('weight_concentration_prior', 10.0)})\n",
      "frozenset({('demonstration key', 7), ('weight_concentration_prior', 20.0)})\n"
     ]
    }
   ],
   "source": [
    "#the models to be trained, as a list of keys\n",
    "test_models = [key({'weight_concentration_prior':float(i), 'demonstration key (does nothing)':7}) for i in range(10, 21, 10)]\n",
    "\n",
    "#makes the training set the first 5000 elements and the test set the last 4800\n",
    "train_size = 5000\n",
    "test_size = 5000\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:train_size+test_size]\n",
    "\n",
    "#for each key\n",
    "for model in test_models:\n",
    "    #if the key is not already in the trained dictionary\n",
    "    if not model in trained_models:\n",
    "        #generate a model with parameters that match the key\n",
    "        m = bgm(model)\n",
    "        \n",
    "        #fit the model to the training data\n",
    "        m.fit(X_train)\n",
    "\n",
    "        #print the model so that you don't have to worry about whether or not the code is working\n",
    "        print(model)\n",
    "\n",
    "        #save the model to the trained models\n",
    "        trained_models[model] = m\n",
    "    \n",
    "    # if the key is not already in the data dictionary\n",
    "    if not model in output_info:\n",
    "        #generate the output info, as a labeled dictionary\n",
    "        info = {}\n",
    "        info['labels'] = trained_models[model].predict(X_test)\n",
    "        info['probs'] = trained_models[model].predict_proba(X_test)\n",
    "        info['log_probs'] = trained_models[model].score_samples(X_test)\n",
    "        info['scores'] = get_measurements(info['log_probs'], df_transactions_copy, train_size, score_function=lambda tps, fps, tns, fns: tps**2 - fps)\n",
    "\n",
    "        #set this last, so that data isn't saved with only half the work done\n",
    "        output_info[model] = info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: this overwrites the previous save files \n",
    "# (this is negated by making sure that the earlier block which adds the save file back into memory\n",
    "# was run)\n",
    "\n",
    "#save the trained models\n",
    "model_output_file = open(model_save_file, 'wb')\n",
    "models_pickler = pickle.Pickler(model_output_file)\n",
    "models_pickler.dump(trained_models)\n",
    "model_output_file.close()\n",
    "\n",
    "#save the test info\n",
    "info_output_file = open(info_save_file, 'wb')\n",
    "info_pickler = pickle.Pickler(info_output_file)\n",
    "info_pickler.dump(output_info)\n",
    "info_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weight_concentration_prior': 10.0}\n",
      "FP:30, TP:16, FN:9, TN:4945, pos:46, neg:4954, flags:25\n",
      "correctly classified fraud:16/25 (64.0%)\n",
      "incorrectly classified normal: 30/4975 (0.6030150753768844%)\n",
      "\n",
      "{'weight_concentration_prior': 20.0}\n",
      "FP:30, TP:16, FN:9, TN:4945, pos:46, neg:4954, flags:25\n",
      "correctly classified fraud:16/25 (64.0%)\n",
      "incorrectly classified normal: 30/4975 (0.6030150753768844%)\n",
      "\n",
      "{'demonstration key': 7, 'weight_concentration_prior': 10.0}\n",
      "FP:82, TP:21, FN:4, TN:4893, pos:103, neg:4897, flags:25\n",
      "correctly classified fraud:21/25 (84.0%)\n",
      "incorrectly classified normal: 82/4975 (1.6482412060301508%)\n",
      "\n",
      "{'demonstration key': 7, 'weight_concentration_prior': 20.0}\n",
      "FP:82, TP:21, FN:4, TN:4893, pos:103, neg:4897, flags:25\n",
      "correctly classified fraud:21/25 (84.0%)\n",
      "incorrectly classified normal: 82/4975 (1.6482412060301508%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print out the stats, for the benefit of everyone who is not a computer\n",
    "for model in output_info:\n",
    "\n",
    "    fp, tp, fn, tn, epsilon = output_info[model]['scores']\n",
    "    #number of transactions marked as suspicious\n",
    "    pos = fp + tp\n",
    "    #number of transactions ignored\n",
    "    neg = fn + tn\n",
    "    #number of fraudulent transactions\n",
    "    flags = tp + fn\n",
    "\n",
    "    print(dict(model))\n",
    "    print(f'FP:{fp}, TP:{tp}, FN:{fn}, TN:{tn}, pos:{pos}, neg:{neg}, flags:{flags}')\n",
    "    print(f'correctly classified fraud:{tp}/{flags} ({tp/flags*100}%)')\n",
    "    print(f'incorrectly classified normal: {fp}/{(output_info[model]['log_probs'].shape[0]-flags)} ({fp/(output_info[model]['log_probs'].shape[0]-flags)*100}%)')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
